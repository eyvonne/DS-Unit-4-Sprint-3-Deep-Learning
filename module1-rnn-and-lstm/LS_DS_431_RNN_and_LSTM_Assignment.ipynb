{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='./100-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, 'r') as data:\n",
    "    content=data.read()\n",
    "sonnets=content.split('\\n')[139:2907]\n",
    "plays=content.split('\\n')[2907:166478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768\n",
      "35.22982791586998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2615"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sonnets))\n",
    "for sonn in sonnets:\n",
    "    try:\n",
    "        int(sonn.strip())\n",
    "        sonnets.remove(sonn)\n",
    "    except:\n",
    "        pass\n",
    "print(sum([len(i) for i in sonnets])/len(sonnets))\n",
    "len(sonnets)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The average line of a sonnet is just over 35 characters, that seems like a good length to do predictions on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maintain the newlines that were taken out before\n",
    "sonnets='\\n'.join(sonnets)\n",
    "#sonnets=sonnets.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31569"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen=35\n",
    "#thats an even divisor of 35 thats small, I have no idea how this will impact things but seems relevant\n",
    "step=3\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "\n",
    "for i in range(0, len(sonnets)-maxlen, step):\n",
    "    sentences.append(sonnets[i:i+maxlen])\n",
    "    next_chars.append(sonnets[maxlen+i])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From fairest creatures we desire in'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(sonnets)))\n",
    "char_index=dict((c,i) for i, c in enumerate(chars))\n",
    "index_char=dict((i,c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y=np.zeros((len(sentences), len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X has three dimensions, the outter dimesion is a list of sequences \n",
    "each sequence is a list of characers stored in a one hot encoding scheme\n",
    "each chara\n",
    "\n",
    "list of one hot encodings of the characters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_index[char]]=1\n",
    "    y[i, char_index[next_chars[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "optimizer=RMSprop(learning_rate=.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " ':': 8,\n",
       " ';': 9,\n",
       " '?': 10,\n",
       " 'A': 11,\n",
       " 'B': 12,\n",
       " 'C': 13,\n",
       " 'D': 14,\n",
       " 'E': 15,\n",
       " 'F': 16,\n",
       " 'G': 17,\n",
       " 'H': 18,\n",
       " 'I': 19,\n",
       " 'J': 20,\n",
       " 'K': 21,\n",
       " 'L': 22,\n",
       " 'M': 23,\n",
       " 'N': 24,\n",
       " 'O': 25,\n",
       " 'P': 26,\n",
       " 'R': 27,\n",
       " 'S': 28,\n",
       " 'T': 29,\n",
       " 'U': 30,\n",
       " 'V': 31,\n",
       " 'W': 32,\n",
       " 'Y': 33,\n",
       " 'a': 34,\n",
       " 'b': 35,\n",
       " 'c': 36,\n",
       " 'd': 37,\n",
       " 'e': 38,\n",
       " 'f': 39,\n",
       " 'g': 40,\n",
       " 'h': 41,\n",
       " 'i': 42,\n",
       " 'j': 43,\n",
       " 'k': 44,\n",
       " 'l': 45,\n",
       " 'm': 46,\n",
       " 'n': 47,\n",
       " 'o': 48,\n",
       " 'p': 49,\n",
       " 'q': 50,\n",
       " 'r': 51,\n",
       " 's': 52,\n",
       " 't': 53,\n",
       " 'u': 54,\n",
       " 'v': 55,\n",
       " 'w': 56,\n",
       " 'x': 57,\n",
       " 'y': 58,\n",
       " 'z': 59,\n",
       " '‘': 60,\n",
       " '’': 61}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(sonnets) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = sonnets[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index_char[next_index]\n",
    "            \n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c',\n",
       " 'a',\n",
       " ',',\n",
       " 'h',\n",
       " ' ',\n",
       " 'e',\n",
       " 'b',\n",
       " 'b',\n",
       " 'u',\n",
       " '’',\n",
       " 'r',\n",
       " 'e',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 'i',\n",
       " '\\n',\n",
       " 't',\n",
       " 's',\n",
       " 'h',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 'u',\n",
       " ' ',\n",
       " ' ',\n",
       " 'm',\n",
       " 'd',\n",
       " 'e',\n",
       " 'e',\n",
       " 'H',\n",
       " ' ',\n",
       " 'n',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'g',\n",
       " ' ',\n",
       " 'a',\n",
       " 'h',\n",
       " ' ',\n",
       " 'm',\n",
       " 'y',\n",
       " 'B',\n",
       " ' ',\n",
       " 'o',\n",
       " 'c',\n",
       " 't',\n",
       " 'c',\n",
       " 'd',\n",
       " 'o',\n",
       " 'h',\n",
       " 'e',\n",
       " 'w',\n",
       " 'b',\n",
       " 'g',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'g',\n",
       " '’',\n",
       " 'f',\n",
       " 'm',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " '-',\n",
       " 'b',\n",
       " 'a',\n",
       " 'i',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'k',\n",
       " 'g',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 'h',\n",
       " 'e',\n",
       " 'b',\n",
       " 'd',\n",
       " 'c',\n",
       " 'l',\n",
       " 's',\n",
       " 'T',\n",
       " ' ',\n",
       " 'l',\n",
       " 't',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " ' ',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 't',\n",
       " ' ',\n",
       " 'u',\n",
       " ':',\n",
       " 'h',\n",
       " ' ',\n",
       " 'a',\n",
       " 'a',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'w',\n",
       " 'l',\n",
       " 's',\n",
       " 'r',\n",
       " 'h',\n",
       " 'r',\n",
       " 'm',\n",
       " 't',\n",
       " 'A',\n",
       " ' ',\n",
       " 'l',\n",
       " 'h',\n",
       " 'a',\n",
       " ' ',\n",
       " ' ',\n",
       " 'e',\n",
       " 'a',\n",
       " 'y',\n",
       " 'p',\n",
       " 'n',\n",
       " '\\n',\n",
       " 't',\n",
       " 'n',\n",
       " 'h',\n",
       " 'e',\n",
       " 'w',\n",
       " 'b',\n",
       " ' ',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'n',\n",
       " 'n',\n",
       " '\\n',\n",
       " 'd',\n",
       " 't',\n",
       " 'd',\n",
       " ' ',\n",
       " 'u',\n",
       " ',',\n",
       " 'a',\n",
       " 's',\n",
       " 'w',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'd',\n",
       " 'g',\n",
       " ' ',\n",
       " 'i',\n",
       " ' ',\n",
       " 'e',\n",
       " 'o',\n",
       " 'd',\n",
       " 'o',\n",
       " 'e',\n",
       " 'e',\n",
       " 'h',\n",
       " ' ',\n",
       " 'u',\n",
       " 'o',\n",
       " 'b',\n",
       " '\\n',\n",
       " 'T',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'o',\n",
       " 'd',\n",
       " ' ',\n",
       " 'e',\n",
       " 'b',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'd',\n",
       " 'h',\n",
       " '.',\n",
       " '\\n',\n",
       " 'h',\n",
       " ' ',\n",
       " 'r',\n",
       " ' ',\n",
       " 'n',\n",
       " 'r',\n",
       " 's',\n",
       " 'l',\n",
       " 'b',\n",
       " 'i',\n",
       " 'e',\n",
       " 'h',\n",
       " 'b',\n",
       " 'w',\n",
       " 'A',\n",
       " ' ',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'h',\n",
       " ' ',\n",
       " ' ',\n",
       " 'y',\n",
       " 'e',\n",
       " 't',\n",
       " 's',\n",
       " 'i',\n",
       " 'd',\n",
       " 'T',\n",
       " ' ',\n",
       " 'u',\n",
       " '’',\n",
       " 'p',\n",
       " 'u',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'z',\n",
       " ' ',\n",
       " ' ',\n",
       " 'w',\n",
       " 'W',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " ' ',\n",
       " 'e',\n",
       " 'o',\n",
       " 's',\n",
       " 'l',\n",
       " 'w',\n",
       " 't',\n",
       " 'h',\n",
       " 'd',\n",
       " 'T',\n",
       " 'n',\n",
       " 'e',\n",
       " 'g',\n",
       " 's',\n",
       " 'd',\n",
       " 'w',\n",
       " 'r',\n",
       " 'a',\n",
       " ' ',\n",
       " 'y',\n",
       " 'e',\n",
       " 't',\n",
       " 'l',\n",
       " 's',\n",
       " 'W',\n",
       " 'r',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'e',\n",
       " 'f',\n",
       " 'h',\n",
       " 'l',\n",
       " 't',\n",
       " 'd',\n",
       " 's',\n",
       " 'T',\n",
       " 's',\n",
       " ',',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 'n',\n",
       " 'o',\n",
       " ' ',\n",
       " 'e',\n",
       " 's',\n",
       " 'k',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'r',\n",
       " 'a',\n",
       " 'a',\n",
       " '-',\n",
       " 't',\n",
       " 'g',\n",
       " 'h',\n",
       " 'e',\n",
       " 'a',\n",
       " ' ',\n",
       " 'r',\n",
       " 't',\n",
       " 's',\n",
       " 'p',\n",
       " 'i',\n",
       " '.',\n",
       " 'o',\n",
       " 'm',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'r',\n",
       " 'd',\n",
       " 'h',\n",
       " 'b',\n",
       " 'u',\n",
       " '’',\n",
       " 'u',\n",
       " ',',\n",
       " 'f',\n",
       " 'h',\n",
       " ' ',\n",
       " 'u',\n",
       " 's',\n",
       " 'a',\n",
       " 'w',\n",
       " ' ',\n",
       " 'h',\n",
       " ' ',\n",
       " 'i',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'h',\n",
       " 'l',\n",
       " 'u',\n",
       " 'm',\n",
       " 'c',\n",
       " 'n',\n",
       " ' ',\n",
       " 'd',\n",
       " 'a',\n",
       " ' ',\n",
       " ' ',\n",
       " 'd',\n",
       " 'x',\n",
       " 's',\n",
       " '’',\n",
       " 'r',\n",
       " 'i',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 't',\n",
       " 'b',\n",
       " 's',\n",
       " 'c',\n",
       " 's',\n",
       " 'n',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " ' ',\n",
       " 'r',\n",
       " 't',\n",
       " 'b',\n",
       " 'n',\n",
       " ' ',\n",
       " 'd',\n",
       " 'w',\n",
       " 'n',\n",
       " 'h',\n",
       " ' ',\n",
       " 't',\n",
       " 'l',\n",
       " '\\n',\n",
       " 'A',\n",
       " ' ',\n",
       " 'e',\n",
       " 'h',\n",
       " 'b',\n",
       " 'o',\n",
       " 'w',\n",
       " 'm',\n",
       " 'h',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " 'l',\n",
       " 't',\n",
       " 't',\n",
       " 'o',\n",
       " '.',\n",
       " '\\n',\n",
       " 'o',\n",
       " ' ',\n",
       " ' ',\n",
       " 'y',\n",
       " 'l',\n",
       " 's',\n",
       " 'n',\n",
       " 't',\n",
       " 'l',\n",
       " 'h',\n",
       " 'f',\n",
       " 'e',\n",
       " 'h',\n",
       " ' ',\n",
       " 'e',\n",
       " 's',\n",
       " '\\n',\n",
       " 'w',\n",
       " 's',\n",
       " 'h',\n",
       " 't',\n",
       " 'e',\n",
       " 'h',\n",
       " ' ',\n",
       " 'c',\n",
       " 's',\n",
       " 'u',\n",
       " ' ',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'r',\n",
       " 'W',\n",
       " 's',\n",
       " 'f',\n",
       " 's',\n",
       " 'r',\n",
       " 'a',\n",
       " ' ',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 'w',\n",
       " 't',\n",
       " 'T',\n",
       " 'u',\n",
       " 'o',\n",
       " ' ',\n",
       " 'g',\n",
       " 'l',\n",
       " 't',\n",
       " ' ',\n",
       " 'r',\n",
       " ',',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'm',\n",
       " 'h',\n",
       " '.',\n",
       " 'o',\n",
       " 'w',\n",
       " 'r',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 'w',\n",
       " 's',\n",
       " 'u',\n",
       " 'a',\n",
       " 'd',\n",
       " 'o',\n",
       " '\\n',\n",
       " 's',\n",
       " 'i',\n",
       " ' ',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " ' ',\n",
       " ' ',\n",
       " 'y',\n",
       " 'u',\n",
       " 'a',\n",
       " 'r',\n",
       " '\\n',\n",
       " ' ',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'o',\n",
       " 'o',\n",
       " ' ',\n",
       " 'l',\n",
       " 'b',\n",
       " 't',\n",
       " ' ',\n",
       " 'm',\n",
       " 'O',\n",
       " 'h',\n",
       " ' ',\n",
       " 'l',\n",
       " 'l',\n",
       " 'e',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 's',\n",
       " 'r',\n",
       " 'y',\n",
       " 'T',\n",
       " 'u',\n",
       " 'r',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'd',\n",
       " 'h',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " 'o',\n",
       " 'l',\n",
       " 'A',\n",
       " 'i',\n",
       " 'o',\n",
       " 'h',\n",
       " ' ',\n",
       " 'i',\n",
       " ',',\n",
       " 'o',\n",
       " 'h',\n",
       " ' ',\n",
       " 'r',\n",
       " 'g',\n",
       " 'w',\n",
       " 'd',\n",
       " 's',\n",
       " 'f',\n",
       " 'h',\n",
       " 'e',\n",
       " 'g',\n",
       " 's',\n",
       " 'l',\n",
       " 's',\n",
       " ',',\n",
       " 'e',\n",
       " 'i',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 'l',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'l',\n",
       " 'n',\n",
       " 'i',\n",
       " '.',\n",
       " ' ',\n",
       " 't',\n",
       " 'f',\n",
       " 'h',\n",
       " ' ',\n",
       " 'v',\n",
       " 'r',\n",
       " 'e',\n",
       " 'e',\n",
       " 'd',\n",
       " 'o',\n",
       " 't',\n",
       " 'b',\n",
       " '\\n',\n",
       " 'D',\n",
       " ' ',\n",
       " 'n',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'n',\n",
       " 'i',\n",
       " 'g',\n",
       " 'd',\n",
       " 's',\n",
       " 'i',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 't',\n",
       " 'i',\n",
       " 'y',\n",
       " 'o',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " ' ',\n",
       " 'o',\n",
       " 's',\n",
       " 'n',\n",
       " '\\n',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'l',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " 'y',\n",
       " ' ',\n",
       " 'g',\n",
       " 'y',\n",
       " 'N',\n",
       " 'u',\n",
       " '’',\n",
       " 'b',\n",
       " 'u',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'i',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'n',\n",
       " '\\n',\n",
       " 'd',\n",
       " 'e',\n",
       " 'g',\n",
       " 'r',\n",
       " 'k',\n",
       " 'h',\n",
       " 'l',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 's',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'e',\n",
       " 'b',\n",
       " 'u',\n",
       " 'o',\n",
       " ' ',\n",
       " 'g',\n",
       " 'r',\n",
       " 'w',\n",
       " ' ',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'b',\n",
       " 'e',\n",
       " 'T',\n",
       " ' ',\n",
       " 'u',\n",
       " 'e',\n",
       " 's',\n",
       " 'a',\n",
       " 'e',\n",
       " ' ',\n",
       " 'v',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'g',\n",
       " 'e',\n",
       " 'P',\n",
       " 'f',\n",
       " 'l',\n",
       " 's',\n",
       " 's',\n",
       " 'e',\n",
       " 'w',\n",
       " ' ',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 's',\n",
       " 'S',\n",
       " 'g',\n",
       " 'a',\n",
       " 'a',\n",
       " 'u',\n",
       " 'o',\n",
       " 's',\n",
       " 's',\n",
       " 'e',\n",
       " 'c',\n",
       " 's',\n",
       " 'n',\n",
       " ' ',\n",
       " 'v',\n",
       " '\\n',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 't',\n",
       " 'f',\n",
       " 'c',\n",
       " 'i',\n",
       " ' ',\n",
       " 'y',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " ',',\n",
       " 'h',\n",
       " ' ',\n",
       " ' ',\n",
       " 'y',\n",
       " 'e',\n",
       " ' ',\n",
       " 'y',\n",
       " 'w',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'd',\n",
       " 'e',\n",
       " 'e',\n",
       " 'T',\n",
       " 'n',\n",
       " 'o',\n",
       " 'w',\n",
       " 'n',\n",
       " 'a',\n",
       " 'r',\n",
       " 'c',\n",
       " 'l',\n",
       " 't',\n",
       " 'e',\n",
       " 'o',\n",
       " 'e',\n",
       " 'o',\n",
       " ',',\n",
       " 'h',\n",
       " ' ',\n",
       " 'c',\n",
       " 't',\n",
       " 'l',\n",
       " 'a',\n",
       " 'i',\n",
       " 'c',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'e',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'u',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'y',\n",
       " 'u',\n",
       " ' ',\n",
       " ' ',\n",
       " 'm',\n",
       " 'd',\n",
       " 'i',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'W',\n",
       " 'c',\n",
       " 'u',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'h',\n",
       " 'e',\n",
       " 'c',\n",
       " 'o',\n",
       " 't',\n",
       " 'b',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'o',\n",
       " ' ',\n",
       " 'u',\n",
       " ' ',\n",
       " 'a',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'w',\n",
       " 'k',\n",
       " 'i',\n",
       " 'f',\n",
       " 'm',\n",
       " 'T',\n",
       " ' ',\n",
       " 'v',\n",
       " 'y',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'o',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'l',\n",
       " 'p',\n",
       " 'y',\n",
       " 'h',\n",
       " 't',\n",
       " 'a',\n",
       " 's',\n",
       " 'o',\n",
       " 'h',\n",
       " 'v',\n",
       " 'y',\n",
       " 'a',\n",
       " ',',\n",
       " 'n',\n",
       " 't',\n",
       " 't',\n",
       " 'n',\n",
       " 'i',\n",
       " 'w',\n",
       " 'c',\n",
       " 'f',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'r',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 'i',\n",
       " ' ',\n",
       " 'm',\n",
       " 'l',\n",
       " 'd',\n",
       " 's',\n",
       " 'm',\n",
       " ' ',\n",
       " '\\n',\n",
       " ' ',\n",
       " 'd',\n",
       " 'u',\n",
       " 'w',\n",
       " 't',\n",
       " ' ',\n",
       " 'd',\n",
       " 'o',\n",
       " 'o',\n",
       " 'd',\n",
       " 'h',\n",
       " ' ',\n",
       " 'e',\n",
       " ',',\n",
       " 'a',\n",
       " 'c',\n",
       " 'c',\n",
       " 'd',\n",
       " 'i',\n",
       " ' ',\n",
       " 'o',\n",
       " ' ',\n",
       " 'd',\n",
       " 'u',\n",
       " 'y',\n",
       " 'e',\n",
       " 'e',\n",
       " 'q',\n",
       " 't',\n",
       " 'g',\n",
       " 'e',\n",
       " 'B',\n",
       " 'u',\n",
       " ' ',\n",
       " 'e',\n",
       " 's',\n",
       " 'w',\n",
       " ' ',\n",
       " 'd',\n",
       " 'a',\n",
       " 'n',\n",
       " 's',\n",
       " 'v',\n",
       " 'y',\n",
       " 'h',\n",
       " 'e',\n",
       " 'T',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'u',\n",
       " 'e',\n",
       " 's',\n",
       " 'i',\n",
       " 'i',\n",
       " 'a',\n",
       " 'o',\n",
       " 'l',\n",
       " 't',\n",
       " ' ',\n",
       " 'q',\n",
       " 'd',\n",
       " 'r',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'l',\n",
       " ' ',\n",
       " ' ',\n",
       " 'a',\n",
       " ',',\n",
       " 'e',\n",
       " 't',\n",
       " 's',\n",
       " 'f',\n",
       " 'c',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " 't',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 'f',\n",
       " '\\n',\n",
       " 'r',\n",
       " 't',\n",
       " 'o',\n",
       " 'n',\n",
       " 'r',\n",
       " 'e',\n",
       " 'r',\n",
       " 'c',\n",
       " 'w',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " '\\n',\n",
       " 'B',\n",
       " ' ',\n",
       " 'o',\n",
       " 'r',\n",
       " 'd',\n",
       " 't',\n",
       " 'l',\n",
       " ' ',\n",
       " 'o',\n",
       " 'h',\n",
       " 'h',\n",
       " ' ',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " ' ',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'L',\n",
       " 's',\n",
       " 'b',\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31569 samples\n",
      "Epoch 1/5\n",
      "31488/31569 [============================>.] - ETA: 0s - loss: 1.7050\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"y precious minutes waste,\n",
      "These vac\"\n",
      "y precious minutes waste,\n",
      "These vace they the still the time the faire the then the time the can the still the time the time thee thee thee the time be the then the time the then the time thee the still the steak then thee thee the self the still the time the stear the still the time the still the self ther the tand the still the self all the still thy self the time the still the still the see the time the steep then thee the still\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"y precious minutes waste,\n",
      "These vac\"\n",
      "y precious minutes waste,\n",
      "These vace this thee heaven time ther thee seet the day,\n",
      "When they thee thee and the me the can the still the self the wite,\n",
      "Thee’ should is the dist all thy pay then devente,\n",
      "The toot and the tide own then thee and then all the tone thee thing for the dead the bost thee,\n",
      "Be not time that thy that me,\n",
      "The till a self to the panswel then the pury make the end his on the steet thee there time,\n",
      "As thy mend by\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"y precious minutes waste,\n",
      "These vac\"\n",
      "y precious minutes waste,\n",
      "These vace.\n",
      "  And lessed oll gatw’ plesidee water,\n",
      "When a oy seen’s sith then I self yet slest,\n",
      "Thy ope.\n",
      "  Af thing vice all an me I says should would not wands arefore’s with own\n",
      "In mught I paraince then when chand to that I fair time?\n",
      "Ther dey,\n",
      "Thy feltertalts will thus natt stlence fife his thest seef have hen thing thee:\n",
      "Thought pay,\n",
      "  As to mo but frict faire arg neve beaw gerfent os unrows frove cons\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"y precious minutes waste,\n",
      "These vac\"\n",
      "y precious minutes waste,\n",
      "These vactless in snain folso aty handet lovelicay withents hethertering all thy nause,\n",
      "That tearhes thee of azare tisefle,\n",
      "Which ale althen oYes thee,\n",
      "Thy sucen of the self nrttcen\n",
      "S oTh wrid,\n",
      "O make for why yron, life end for win lair’s prire,\n",
      "of okane mineriwt’s imonded will have op thy s tubqueshit selfow I have fulst agel bmong tTo thy by gain,\n",
      "Alay geecy, when in is hould thy make,\n",
      "  in theeed that s\n",
      "31569/31569 [==============================] - 67s 2ms/sample - loss: 1.7050\n",
      "Epoch 2/5\n",
      "31488/31569 [============================>.] - ETA: 0s - loss: 1.6033\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"te or ruining?\n",
      "Have I not seen dwel\"\n",
      "te or ruining?\n",
      "Have I not seen dwell the wilk still and the time the wilk thee the hall the time that the wilk do thee the hall live will the love the still will the but thee and thee the time the worth the the still shall I master with thy self all the forth my self the wilk the worth I mage the lay thy self some I that thee the time will and beauty the wilk and the time the love to the that the love the wilk still the thee the be\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"te or ruining?\n",
      "Have I not seen dwel\"\n",
      "te or ruining?\n",
      "Have I not seen dwell comprace that I fires have burs part,\n",
      "Or bestered with beauty make to the dest thee, and the time morpent heart that on the tomm though art which thee I my find’s that which the viety the him thee, Inethand thee last nor find the raye the that it all the worth which ame mage his thy love the wilkered the wilk mind bursed thee,\n",
      "The nake thou art hame in thee for the self my hart,\n",
      "That append.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"te or ruining?\n",
      "Have I not seen dwel\"\n",
      "te or ruining?\n",
      "Have I not seen dwell that do my light’s scame I nenciight,\n",
      "In seetCsestew\n",
      "Wishy listion but event’re,\n",
      "  Save,\n",
      "But death to the deeleneth knamines time,\n",
      "But not this digdwicky I toltrs woe thy subplerd werery serful thy tomb, decriet ant your humould ontings basteme sick.\n",
      "\n",
      "\n",
      "\n",
      "And is wat summer disgrowe.\n",
      "  Indils so bride?\n",
      "And price,\n",
      "in this thou is she bligteap thy allite I love’s delring his collught,\n",
      "Time:\n",
      "    And h\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"te or ruining?\n",
      "Have I not seen dwel\"\n",
      "te or ruining?\n",
      "Have I not seen dwelt wilkle as tolkneth miny laske’s foiored bo giy,\n",
      "Uf to plamely ole,\n",
      "bankhing idfreeigs,\n",
      "His you ghing thiteeryan’s flapy be bi mand.\n",
      "\n",
      "  For spenty of inwuend.\n",
      "But my wirour netsankes is from say\n",
      "Which my seliwaling bnough againy;\n",
      "\n",
      "\n",
      "\n",
      "Wint metot:\n",
      "And hoth art anqwentdetidy.\n",
      "  Onarthy creath, phould widhing hubreal ale pris his sine\n",
      "extrand’uth in tenkerss my iliminc slanterening pents?\n",
      "Thesholthce \n",
      "31569/31569 [==============================] - 66s 2ms/sample - loss: 1.6036\n",
      "Epoch 3/5\n",
      "31488/31569 [============================>.] - ETA: 0s - loss: 1.5596\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"gns love and all love’s loving part\"\n",
      "gns love and all love’s loving part to the tell the dest to the tood the toods to me the seed thou art the world dead,\n",
      "The words but thou the time the self and the the fair the world the dose the love to beauty the love,\n",
      "But the time the world the time the world in the tood the too the world the to the world the world the world the truth which the part the love to be the too the the seed the praise to the see the tood the self the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"gns love and all love’s loving part\"\n",
      "gns love and all love’s loving part to the my spice to my have the lessed,\n",
      "And the all and suemest of me shall the may the least of the ceave and the con the can the words with the world the pacest not the strengue the love to me thine on the shall that my mand my world the fair of that mine my self thee that the self have the see tell and words to my lovs and thou art and best back be wome the cannce have that deather that the lov\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"gns love and all love’s loving part\"\n",
      "gns love and all love’s loving partters have mind:\n",
      "The sumen’ly far seet,\n",
      "Ub\n",
      "For have thou dis my speek,\n",
      "For the"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eyvonnegeordan/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hambmars not can have for even mink Lels for arteet a beclence,\n",
      "Wece bark-ersu   Timed not when nough in thy everyt that will though praise he provine times I divines woed deplate.\n",
      "\n",
      "\n",
      "\n",
      "So stant in mend my coldentate on my storing the gabled, thou bright,\n",
      "All the ove,\n",
      "  Which I have do thee,\n",
      "and  vew I wombs so carvingr of\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"gns love and all love’s loving part\"\n",
      "gns love and all love’s loving parttancked but of on thou of from more,\n",
      "  So shall in his that keep for times lovely then bett now madetben’st I the beauty lebd bloakting:\n",
      "But peidit,\n",
      "\n",
      "\n",
      "\n",
      "In they which them faur rid gruder we one thing bul wost; truth?\n",
      "When dyes re!\n",
      "y more crobl Tendake bandmed make for by herringrent woild leemerored then in couls inuon deathss and their thou vicht when thou wilt to effared confargeful of the eyely\n",
      "31569/31569 [==============================] - 218s 7ms/sample - loss: 1.5587\n",
      "Epoch 4/5\n",
      "31488/31569 [============================>.] - ETA: 0s - loss: 1.5153\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e time’s spoils despised everywhere\"\n",
      "e time’s spoils despised everywhere that the dost the price,\n",
      "The world for the love the sweet read, and whilt the love the still, and the mourn the world that the live thee the love, the time thou art the world the time the love that worth that the would the world still the still the live thee the delich not thou far the love the dear thee where the could to the world that the tood the still that the time the poured and the still, \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e time’s spoils despised everywhere\"\n",
      "e time’s spoils despised everywhere with the cound like that wilt respice.\n",
      "\n",
      "\n",
      "\n",
      "The canswere the mows I were thou may what show whilk I there I when whilst this it thy lend dellevile that mistries,\n",
      "To love live a couldst may me to still be the parice the libus rewlice that forchul day to might,\n",
      "Who lideus thou frown, virts thee, and thou wilt the love whilt that ourt may sain mo that I thine thou was my live me me fill you in thy lov\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e time’s spoils despised everywhere\"\n",
      "e time’s spoils despised everywhered meuur the blads to dore veir pant; wemirich healt tell,\n",
      "And be.\n",
      "Who othersire infrowed then morn thou all the beint orit still not it that and silr of wreit ource thl quilt take, and adlinded onemind,\n",
      "Ialich thee conbing one propws the my tume day.\n",
      "That by new widh I bluge thou, a carure of the dids,\n",
      "  And and you thy full,\n",
      "And beworn frown of the eblere,\n",
      "The storns to faires resmam still, what \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e time’s spoils despised everywhere\"\n",
      "e time’s spoils despised everywhered thy bests deesprer,\n",
      "Thine own thou to tongs for compercoired, iten’s liel To mine imour womm’s dised own this blad,\n",
      "Doth groud,\n",
      "By jrist,\n",
      "Then gild imtood nuswer and (shadut templry’s lich mine  Thre wear wound dike busured bend’st as chessed\n",
      "When are would frowerence nonge time.\n",
      "In may lext couldsure upnepurire removesle I tith though deceition heavy to silfen I gefory, if not behointing thy se\n",
      "31569/31569 [==============================] - 73s 2ms/sample - loss: 1.5153\n",
      "Epoch 5/5\n",
      "31488/31569 [============================>.] - ETA: 0s - loss: 1.4712\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ithin the level of your frown,\n",
      "But \"\n",
      "ithin the level of your frown,\n",
      "But the see the still thee the streng thee the see the still thee the seeven the summer thee the sweet with thee and the sweet and words are thee the see the way for the still thee the steak with the world the world the still the still the strenged and submed with the see the way seesery self the way warth and warth the still see the stard that seef the see the love thee the strence thee there they th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ithin the level of your frown,\n",
      "But \"\n",
      "ithin the level of your frown,\n",
      "But way he being have me hop which in one on the ure,\n",
      "In of the self for have shalt what thou love thee.\n",
      "  When in the story and that my self a fair in the way deterved and beauty’s sweet shall he love fair be all thee have so stay soul thou so for the cound thy prainst word be fair not the eyes do pace\n",
      "To be for he blain,\n",
      "The live thee a steet in the some, and are thee and do thee weeds to seek a ver\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ithin the level of your frown,\n",
      "But \"\n",
      "ithin the level of your frown,\n",
      "But then par so forth:\n",
      "And thou this mids ind that time do vience beeds I cound to hainst my a verd.\n",
      "\n",
      "\n",
      "\n",
      "  A  chust and price of sikned, and I eye I fair doth up my love all looking heavy not paides a but aftern melord to heakent a suplames herr chat brest time,\n",
      "And that slook again aw’s beway do genoictlen’s pace fap the hear deades it I have behore to heed looks tood and argencied,\n",
      "Of may feadmed it:\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ithin the level of your frown,\n",
      "But \"\n",
      "ithin the level of your frown,\n",
      "But made part deceivedoned,\n",
      "to ligh it wanky vieging cod there for mist to menrance reath every my mair’s like and love by self mine? rewleve, to wrete,\n",
      "  erriet ears priin that vevy night\n",
      "I noth wich wootdyt deeds,\n",
      "Nor every home morn,\n",
      "For his though \n",
      "In thy self itwu of nepgry,\n",
      "is such I midale a knowed,\n",
      "I one day,\n",
      "Doth below’st thou verds of when dide:\n",
      "If (in in me.\n",
      "\n",
      "\n",
      "\n",
      "rhyer hempard summer are fect\n",
      "31569/31569 [==============================] - 69s 2ms/sample - loss: 1.4711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x31b310b38>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
